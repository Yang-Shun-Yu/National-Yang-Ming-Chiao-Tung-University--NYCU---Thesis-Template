\begin{abstractzh}

隨著城市智能交通系統的迅速發展，多攝像頭車輛追踪技術在交通監控、公共安全與城市規劃等領域中扮演著愈發重要的角色。然而，部分鄉村地區的監控系統常因硬體限制及網絡通訊不佳，導致更新頻率極低（例如僅1幀/秒）甚至出現畫面卡頓，傳統基於高幀率的追踪方法在此環境下難以保持穩定與準確性。為解決此一問題，本論文提出一種融合深度度量學習與運動預測技術的低幀率多攝像頭車輛追踪方法。

首先，本研究比較了基於卷積神經網絡（CNN）與Transformer兩種深度學習模型架構，其設計靈感分別源自《A Strong Baseline and Batch Normalization Neck for Deep Person Re-identification》與《TransReID: Transformer-based Object Re-Identification》。在模型訓練階段，我們同時採用了center loss, triplet loss與cross entropy loss，以提升模型對車輛特徵的識別能力；而在推理階段，則利用模型提取車輛外觀特徵，並透過計算特徵向量之間的餘弦相似度進行匹配。

其次，針對低幀率及畫面不連續等挑戰，本文引入了運動預測方法，分別採用簡單線性預測與卡爾曼濾波預測兩種策略。該方法根據連續幀中車輛位置的變化，預測下一幀中車輛可能出現的位置，並通過降低匹配閾值來輔助車輛再識別。

此外，為進一步提高追踪準確性，本文結合了正向追踪與反向追踪策略。首先，在單一監視器下完成車輛追踪，將相同車輛歸類；隨後，利用這些單鏡頭追踪結果進行跨鏡頭匹配，從而識別出同一車輛在不同監視器畫面中的出現情況。實驗結果顯示，即使在低幀率與畫面不連續的條件下，該方法仍能保持良好的追踪效果與準確性，為實際交通監控應用提供了一種有效的解決方案。

\vspace{17cm}

關鍵詞：低幀率、多攝像頭追踪、深度度量學習、車輛再識別、運動預測、卡爾曼濾波

\end{abstractzh}